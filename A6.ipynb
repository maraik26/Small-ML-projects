{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 6: Pratical Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine you want to build a classification model for your company. It's not uncommon that you may encounter the following three problems:\n",
    "\n",
    "* There is no training data available; data labeling may cost you a lot of money and time.\n",
    "* The number of features is very large, which may not only lead to long training time but also hurt model generalization. \n",
    "* There are a number of parameters associated with your model, and you do not know what parameters should be used. \n",
    "\n",
    "In this assignment, you will learn how to use Active Learning to address the first problem, learn how to apply a feature selection approach as well as Principal Component Analysis (PCA) to addressing the second one, and learn how to use the Spark ML pipeline API to tune parameters.\n",
    "\n",
    "\n",
    "After completing this assignment, you should be able to answer the following questions:\n",
    "\n",
    "**Data Labeling**\n",
    "1. Why Active Learning?\n",
    "2. How to implement uncertain sampling, a popular query strategy for Active Learning?\n",
    "3. How to solve an ER problem using Active Learning?\n",
    "\n",
    "**Feature Selection**\n",
    "1. Why Feature Selection?\n",
    "2. What are typical Feature Selection approaches?\n",
    "3. How does a filter-based feature selection approach work?\n",
    "4. How does PCA work?\n",
    "5. What're the advantages and disadvantages of PCA? \n",
    "\n",
    "**Parameter Tuning**\n",
    "1. Why parameter tuning?\n",
    "2. What is cross-validation?\n",
    "3. What is areaUnderROC?\n",
    "4. How to tune parameters?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font color=\"blue\">Note: In this assignment, the example code was writtin for Python 2. If you use Python 3, please feel free to make changes (e.g., print x --> print(x)). </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Data Labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Active learning](http://tiny.cc/al-wiki) is a certain type of ML algorithms that can train a high-quality ML model with small data-labeling cost. Its basic idea is quite easy to understand. Consider a typical supervised ML problem, which requires a (relatively) large training dataset. In the training dataset, there may be only a small number of data points that are beneficial to the trained ML model. In other words, labeling the small number of data points is enough to train a high-quality ML model. The goal of active learning is to help us to identify the data points. \n",
    "\n",
    "\n",
    "In this assignment, we will revisit [Entity Resolution](https://sfu-db.github.io/bigdata-cmpt733/Lectures/lec2.pdf) and develop an Active Learning approach for it. Recall that entity Resolution (ER) is defined as finding different records that refer to the same real-world entity, e.g., \"iPhone 4-th Generation\" vs. \"iPhone Four\". It is central to data integration and cleaning. The following figure shows the architecture of an entity resolution solution. It consists of four major steps. **I will provide you the source code for Steps 1, 2, 4. Your job is to implement Step 3.**  \n",
    "\n",
    "<img src=\"img/arch.png\", width=800/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Read Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [restaurant data](restaurant.csv) is in an CSV file. Here is the code to read it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(#Rows, #Cols) : (858, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>arnie morton's of chicago</td>\n",
       "      <td>435 s. la cienega blv.</td>\n",
       "      <td>los angeles</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>arnie morton's of chicago</td>\n",
       "      <td>435 s. la cienega blvd.</td>\n",
       "      <td>los angeles</td>\n",
       "      <td>steakhouses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>art's delicatessen</td>\n",
       "      <td>12224 ventura blvd.</td>\n",
       "      <td>studio city</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>art's deli</td>\n",
       "      <td>12224 ventura blvd.</td>\n",
       "      <td>studio city</td>\n",
       "      <td>delis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>hotel bel-air</td>\n",
       "      <td>701 stone canyon rd.</td>\n",
       "      <td>bel air</td>\n",
       "      <td>californian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>bel-air hotel</td>\n",
       "      <td>701 stone canyon rd.</td>\n",
       "      <td>bel air</td>\n",
       "      <td>californian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>cafe bizou</td>\n",
       "      <td>14016 ventura blvd.</td>\n",
       "      <td>sherman oaks</td>\n",
       "      <td>french</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>cafe bizou</td>\n",
       "      <td>14016 ventura blvd.</td>\n",
       "      <td>sherman oaks</td>\n",
       "      <td>french bistro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                       name                  address          city  \\\n",
       "0   1  arnie morton's of chicago   435 s. la cienega blv.   los angeles   \n",
       "1   2  arnie morton's of chicago  435 s. la cienega blvd.   los angeles   \n",
       "2   3         art's delicatessen      12224 ventura blvd.   studio city   \n",
       "3   4                 art's deli      12224 ventura blvd.   studio city   \n",
       "4   5              hotel bel-air     701 stone canyon rd.       bel air   \n",
       "5   6              bel-air hotel     701 stone canyon rd.       bel air   \n",
       "6   7                 cafe bizou      14016 ventura blvd.  sherman oaks   \n",
       "7   8                 cafe bizou      14016 ventura blvd.  sherman oaks   \n",
       "\n",
       "            type  \n",
       "0       american  \n",
       "1    steakhouses  \n",
       "2       american  \n",
       "3          delis  \n",
       "4    californian  \n",
       "5    californian  \n",
       "6         french  \n",
       "7  french bistro  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('restaurant.csv')\n",
    "data = df.values.tolist()\n",
    "print(\"(#Rows, #Cols) :\", df.shape)\n",
    "df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this dataset, you will find many matching record pairs. For example, the first two rows shown above are matching (i.e., refer to the same real-world entity). You can check out all matching record pairs in the [true_matches.json](true_matches.json) file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Remove Obviously Non-matching Pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A naive implementation of entity resolution is to enumerate all $n^2$ pairs and check whether they are matching or not. As you've learnt in [Assignment 2](https://rawgit.com/sfu-db/bigdata-cmpt733/master/Assignments/A2/A2.html), we can avoid $n^2$ comparisons using a similarity-join algorithm. \n",
    "\n",
    "Here is the code. After running the code, you will get 678 similar pairs ordered by their similarity decreasingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from a9_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Pairs:  367653.0\n",
      "Num of Similar Pairs:  678\n",
      "The Most Similar Pair:  ([170, \"mary mac's tea room\", '224 ponce de leon ave.', 'atlanta', 'southern/soul'], [169, \"mary mac's tea room\", '224 ponce de leon ave.', 'atlanta', 'southern'])\n"
     ]
    }
   ],
   "source": [
    "data = df.values.tolist()\n",
    "simpairs = simjoin(data)\n",
    "print (\"Num of Pairs: \", len(data)*(len(data)-1)/2)\n",
    "print (\"Num of Similar Pairs: \", len(simpairs))\n",
    "print (\"The Most Similar Pair: \", simpairs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that `simjoin` helps us remove the number of pairs from 367653 to 678. But, there are still many non-matching pairs in `simpairs` (see below). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([764, \"buzio's in the rio\", '3700 w. flamingo rd.', 'las vegas', 'seafood'], [542, 'carnival world', '3700 w. flamingo rd.', 'las vegas', 'buffets'])\n"
     ]
    }
   ],
   "source": [
    "print (simpairs[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use active learning to train a classifier, and then use the classifier to classify each pair in `simpairs` as either \"matching\" or \"nonmatching\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Active Learning (Task A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a set of similar pairs, what you need to do next is to iteratively train a classifier to decide which pairs are truly matching. We are going to use [logistic regression](https://en.wikipedia.org/wiki/Logistic_regression) as our classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Featurization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the model, the first thing you need to think about is how to featurize data. That is, transforming each similar pair to a feature vector. Please use the `featurize()` function for featurization. The function takes a pair as input and returns a vector of 6 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature vector of the first pair:  (1.0, 1.0, 1.0, 1.0, 1.0, 0.6)\n"
     ]
    }
   ],
   "source": [
    "from a9_utils import featurize\n",
    "\n",
    "print (\"The feature vector of the first pair: \", featurize(simpairs[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the beginning, all the pairs are unlabeled. To initialize a model, we first pick up ten pairs and then label each pair using  the `crowdsourcing()` function. You can assume that `crowdsourcing()` will ask a crowd worker (e.g., on Amazon Mechanical Turk) to label a pair. \n",
    "\n",
    "\n",
    "`crowdsourcing(pair)` is a function that simulates the use of crowdsourcing to label a pair\n",
    "  \n",
    "  - **Input:**\tpair – A pair of records \n",
    "\n",
    "  - **Output:**\tBoolean –  *True*: The pair of records are matching; *False*: The pair of records are NOT matching;\n",
    "\n",
    "Please use the following code to do the initialization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mAre they matching?\u001b[0m\n",
      "[170, \"mary mac's tea room\", '224 ponce de leon ave.', 'atlanta', 'southern/soul']\n",
      "[169, \"mary mac's tea room\", '224 ponce de leon ave.', 'atlanta', 'southern']\n",
      "\u001b[1;31mAnswer: Yes\u001b[0m\n",
      "\u001b[1;31mAre they matching?\u001b[0m\n",
      "[88, 'manhattan ocean club', '57 w. 58th st.', 'new york city', 'seafood']\n",
      "[87, 'manhattan ocean club', '57 w. 58th st.', 'new york', 'seafood']\n",
      "\u001b[1;31mAnswer: Yes\u001b[0m\n",
      "\u001b[1;31mAre they matching?\u001b[0m\n",
      "[112, 'san domenico', '240 central park s.', 'new york city', 'italian']\n",
      "[111, 'san domenico', '240 central park s', 'new york', 'italian']\n",
      "\u001b[1;31mAnswer: Yes\u001b[0m\n",
      "\u001b[1;31mAre they matching?\u001b[0m\n",
      "[197, 'fleur de lys', '777 sutter st.', 'san francisco', 'french (new)']\n",
      "[196, 'fleur de lys', '777 sutter st.', 'san francisco', 'french']\n",
      "\u001b[1;31mAnswer: Yes\u001b[0m\n",
      "\u001b[1;31mAre they matching?\u001b[0m\n",
      "[8, 'cafe bizou', '14016 ventura blvd.', 'sherman oaks', 'french bistro']\n",
      "[7, 'cafe bizou', '14016 ventura blvd.', 'sherman oaks', 'french']\n",
      "\u001b[1;31mAnswer: Yes\u001b[0m\n",
      "\u001b[1;31mAre they matching?\u001b[0m\n",
      "[709, 'arcadia', '21 e. 62nd st.', 'new york city', 'american (new)']\n",
      "[66, 'four seasons', '99 e. 52nd st.', 'new york city', 'american (new)']\n",
      "\u001b[1;31mAnswer: No\u001b[0m\n",
      "\u001b[1;31mAre they matching?\u001b[0m\n",
      "[709, 'arcadia', '21 e. 62nd st.', 'new york city', 'american (new)']\n",
      "[70, 'gramercy tavern', '42 e. 20th st.', 'new york city', 'american (new)']\n",
      "\u001b[1;31mAnswer: No\u001b[0m\n",
      "\u001b[1;31mAre they matching?\u001b[0m\n",
      "[729, 'la grenouille', '3 e. 52nd st.', 'new york city', 'french (classic)']\n",
      "[60, 'daniel', '20 e. 76th st.', 'new york city', 'french (new)']\n",
      "\u001b[1;31mAnswer: No\u001b[0m\n",
      "\u001b[1;31mAre they matching?\u001b[0m\n",
      "[733, 'menchanko-tei', '39 w. 55th st.', 'new york city', 'japanese']\n",
      "[76, 'la caravelle', '33 w. 55th st.', 'new york city', 'french (classic)']\n",
      "\u001b[1;31mAnswer: No\u001b[0m\n",
      "\u001b[1;31mAre they matching?\u001b[0m\n",
      "[764, \"buzio's in the rio\", '3700 w. flamingo rd.', 'las vegas', 'seafood']\n",
      "[542, 'carnival world', '3700 w. flamingo rd.', 'las vegas', 'buffets']\n",
      "\u001b[1;31mAnswer: No\u001b[0m\n",
      "Number of matches:  5\n",
      "Number of nonmatches:  5\n"
     ]
    }
   ],
   "source": [
    "from a9_utils import crowdsourcing\n",
    "\n",
    "# choose the most/least similar five pairs as initial training data\n",
    "init_pairs = simpairs[:5] + simpairs[-5:]\n",
    "matches = []\n",
    "nonmatches = []\n",
    "for pair in init_pairs:\n",
    "    is_match = crowdsourcing(pair)\n",
    "    if is_match == True:\n",
    "        matches.append(pair)\n",
    "    else:\n",
    "        nonmatches.append(pair)\n",
    "        \n",
    "print (\"Number of matches: \", len(matches))\n",
    "print (\"Number of nonmatches: \", len(nonmatches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame.from_records(nonmatches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interactive Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the only code you need to write in Part 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from a9_utils import featurize, crowdsourcing\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "labeled_pairs = matches + nonmatches\n",
    "unlabeled_pairs = [p for p in simpairs if p not in labeled_pairs]\n",
    "iter_num = 5\n",
    "#<-- Write Your Code -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#featurize(unlabeled_pairs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#labeled_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#featurize(labeled_pairs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mAre they matching?\u001b[0m\n",
      "[240, \"ed debevic's\", '134 n. la cienega', 'los angeles', 'american']\n",
      "[237, \"drai's\", '730 n. la cienega blvd.', 'los angeles', 'french']\n",
      "\u001b[1;31mAnswer: No\u001b[0m\n",
      "5 matches\n",
      "6 nonmatches\n",
      "11 labeled\n",
      "667 unlabeled\n",
      "\u001b[1;31mAre they matching?\u001b[0m\n",
      "[388, 'la reserve', '4 w. 49th st.', 'new york', 'french']\n",
      "[78, 'la cote basque', '60 w. 55th st.', 'new york city', 'french (classic)']\n",
      "\u001b[1;31mAnswer: No\u001b[0m\n",
      "5 matches\n",
      "7 nonmatches\n",
      "12 labeled\n",
      "666 unlabeled\n",
      "\u001b[1;31mAre they matching?\u001b[0m\n",
      "[156, 'ciboulette restaurant', '1529 piedmont ave.', 'atlanta', 'french (new)']\n",
      "[155, 'ciboulette', '1529 piedmont ave.', 'atlanta', 'french']\n",
      "\u001b[1;31mAnswer: Yes\u001b[0m\n",
      "6 matches\n",
      "7 nonmatches\n",
      "13 labeled\n",
      "665 unlabeled\n",
      "\u001b[1;31mAre they matching?\u001b[0m\n",
      "[174, \"pano's & paul's\", '1232 w. paces ferry rd.', 'atlanta', 'american (new)']\n",
      "[173, \"pano's and paul's\", '1232 w. paces ferry rd.', 'atlanta', 'international']\n",
      "\u001b[1;31mAnswer: Yes\u001b[0m\n",
      "7 matches\n",
      "7 nonmatches\n",
      "14 labeled\n",
      "664 unlabeled\n",
      "\u001b[1;31mAre they matching?\u001b[0m\n",
      "[729, 'la grenouille', '3 e. 52nd st.', 'new york city', 'french (classic)']\n",
      "[76, 'la caravelle', '33 w. 55th st.', 'new york city', 'french (classic)']\n",
      "\u001b[1;31mAnswer: No\u001b[0m\n",
      "7 matches\n",
      "8 nonmatches\n",
      "15 labeled\n",
      "663 unlabeled\n"
     ]
    }
   ],
   "source": [
    "iter_numn = 5\n",
    "label = [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
    "while iter_num >0:\n",
    "    col = []\n",
    "    for eachlp in labeled_pairs:\n",
    "        p = featurize(eachlp)\n",
    "        t = col.append(p)\n",
    "    \n",
    "    col2 = []\n",
    "    for eachlp in unlabeled_pairs:\n",
    "        p = featurize(eachlp)\n",
    "        #print (p)\n",
    "        t = col2.append(p)\n",
    "        \n",
    "    dfu = pd.DataFrame.from_records(col2, columns = [\"f1\", \"f2\", \"f3\", \"f4\", \"f5\", \"f6\"])\n",
    "    df = pd.DataFrame.from_records(col, columns = [\"f1\", \"f2\", \"f3\", \"f4\", \"f5\", \"f6\"])\n",
    "    \n",
    "    \n",
    "    lsvc = LogisticRegression(penalty=\"l1\", dual=False).fit(df, label)\n",
    "    model = lsvc.predict_proba(dfu)\n",
    "    \n",
    "    dataframe=pd.DataFrame(model)\n",
    "    dataframe.columns = ['notmatch', 'match']\n",
    "    dataframe['median']= 0.5\n",
    "    dataframe['difference'] = abs(dataframe['median'] - dataframe['notmatch'])\n",
    "    k = dataframe.sort_values(by=['difference'])\n",
    "    kk = unlabeled_pairs[k.index[0]]\n",
    "    \n",
    "    iss_match = crowdsourcing(kk)\n",
    "    if iss_match == True:\n",
    "        matches.append(kk) \n",
    "        label.append(1)\n",
    "    else:\n",
    "        nonmatches.append(kk)\n",
    "        label.append(0)\n",
    "    print(len(matches), \"matches\")   \n",
    "    print(len(nonmatches), \"nonmatches\") \n",
    "    \n",
    "    iter_num = iter_num - 1\n",
    "    \n",
    "    labeled_pairs = matches + nonmatches\n",
    "    unlabeled_pairs = [p for p in simpairs if p not in labeled_pairs]\n",
    "    \n",
    "    print(len(labeled_pairs), \"labeled\")\n",
    "    print(len(unlabeled_pairs), \"unlabeled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Algorithm Description].**   Active learning has many [query strategies](http://tiny.cc/al-wiki-qs) to decide which data point should be labeled. You need to implement uncertain sampling for Task A. The algorithm trains an initial model on `labeled_pairs`. Then, it iteratively trains a model. At each iteration, it first applies the model to `unlabeled_pairs`, and makes a prediction on each unlabeled pair along with a probability, where the probability indicates the confidence of the prediction. After that, it selects the most uncertain pair (If there is still a tie, break it randomly),  and call the `crowdsroucing()` function to label the pair. After the pair is labeled, it updates `labeled_pairs` and `unlabeled_pairs`, and then retrain the model on `labeled_pairs`.\n",
    "\n",
    "**[Input].** \n",
    "- `labeled_pairs`: 10 labeled pairs (by default)\n",
    "- `unlabeled_pairs`: 668 unlabeled pairs (by default)\n",
    "- `iter_num`: 5 (by default)\n",
    "\n",
    "**[Output].** \n",
    "- `model`: A logistic regression model built by scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Precision, Recall](https://en.wikipedia.org/wiki/Precision_and_recall), [F-Score](https://en.wikipedia.org/wiki/F1_score) are commonly used to evaluate an entity-resolution result. After training an model, you can use the following code to evalute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from a9_utils import evaluate\n",
    "from scipy import sparse\n",
    "            \n",
    "sp_features = np.array([featurize(sp) for sp in simpairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8584070796460177\n",
      "Recall: 0.9150943396226415\n",
      "Fscore: 0.8858447488584474\n"
     ]
    }
   ],
   "source": [
    "label1 = lsvc.predict(sp_features)\n",
    "pair_label = zip(simpairs, label1)\n",
    "\n",
    "identified_matches = []\n",
    "for pair, label1 in pair_label:\n",
    "    if label1 == 1:\n",
    "        identified_matches.append(pair)\n",
    "        \n",
    "precision, recall, fscore = evaluate(identified_matches)\n",
    "\n",
    "print (\"Precision:\", precision)\n",
    "print (\"Recall:\", recall)\n",
    "print (\"Fscore:\", fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection and dimensionality reduction have been extensively studied in the ML community. In this part, I designed two simple tasks for you to get familiar with these topics. If you want to know more, please refer to Prof. Michael Jordan's [Practical Machine Learning](https://people.eecs.berkeley.edu/~jordan/courses/294-fall09/) course at UC Berkeley. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task B. Filter-based Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are [three classes](https://en.wikipedia.org/wiki/Feature_selection#Main_principles) of feature-selection methods: filter-based, wrapper-based, and embeded-based. Filter-based is the most simple one. Its basic idea is to assign a heuristic score to each feature to filter out the \"obviously\" useless ones. There are many ways to compute the score, e.g., chi-squared, information gain, correlation, and mutual information. We use [chi-squared](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html) for Task B. \n",
    "\n",
    "Imagine you have a collection of newsgroup documents, and you want to build a classification model to predicate the topic of each newsgroup document: \"comp.graphics (0)\" or \"sci.space (1)\". You use bag of words to represent each document. That is, each feature is a single word. I have already helped you load the dataset and generated the feature vectors (see the code below). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Labels: ['comp.graphics', 'sci.space']\n",
      "(NSamples, NFeatures): (1177, 19493)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "data_train = fetch_20newsgroups(subset='train', categories=['comp.graphics','sci.space'],\n",
    "                                shuffle=True, random_state=42,\n",
    "                                remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(data_train.data)\n",
    "y = data_train.target\n",
    "\n",
    "print (\"Target Labels:\", data_train.target_names)\n",
    "print (\"(NSamples, NFeatures):\", X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output of the above code, you find that the number of features (19493) is very large, so you want to use a filter-based method to choose the top-10 words as your features. \n",
    "\n",
    "Please write your code below. The code computes chi-squared stat between each feature and the target label, and return the top-10 words with the highest score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#model\n",
    "X_new = SelectKBest(chi2, k=10).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1045,  7760,  7763,  8633,  9483, 11963, 12191, 12850, 16345, 19088], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get indeces\n",
    "idxs_selected = X_new.get_support(indices=True)\n",
    "idxs_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3d', 'file', 'files', 'graphics', 'image', 'moon', 'nasa', 'orbit', 'space', 'windows']\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "feature_names = [feature_names[i] for i in idxs_selected]\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task C. Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA is a well-known dimensionality reduction algorithm. Obviously, we can use PCA to transform each feature vector to a 10-D feature vector. See the code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01690229  0.00799231  0.00645213  0.00520591  0.00476723  0.00446176\n",
      "  0.00416202  0.00391218  0.00383937  0.00362904]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(X.toarray())\n",
    "print (pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both filter-based feature selection and PCA can help us reduce the number of features in a feature vector. The question is what's the difference between them. In this task, you don't need to write any code. Just let me know what you think about the advantages and disadvantages of PCA compared to filter-based feature section. Please list (at least) two advantages and two disadvantages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advantages of PCA**\n",
    " - Preserve the variance of the data, Filter-based doesn't.\n",
    " - Combines similar (correlated) attributes and creates new ones that are superior to original attributes. \n",
    " - Benefit in PCA is that combination of N attributes is better than any individual attribute. \n",
    "\n",
    "**Disadvantages of PCA**\n",
    "- The increasing overfitting risk when the number of observations is insufficient. \n",
    "- PCA requires he significant computation time when the number of variables is large. On the other hand Filter-based method is     particularly effective in computation time and robust to overfitting.\n",
    "- PCA method does not support sparse input.\n",
    "- It is hard to explan what exactly that PCA component means. Less understandable than Filter-based selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine you have a collection of newsgroup documents, and you want to build a classification model to predicate the topic of each newsgroup document: \"science (1)\" or \"non-science (0)\". Here is the Spark program (below) that can help you to finish the job. ** Your preliminary task is to read the code and understand how it works. ** I highly recommend you to read through the [Spark ML Pipeline Programming Guide](http://spark.apache.org/docs/latest/ml-pipeline.html), which is very well written, and will aid your understanding of the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7486382404197065\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "\n",
    "trainDF = spark.read.parquet(\"20news_train.parquet\")\n",
    "\n",
    "# Configure an ML pipeline, which consists of three stages: tokenizer, hashingTF, and lr.\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\", numFeatures=1000)\n",
    "lr = LogisticRegression(maxIter=20, regParam=0.1)\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])\n",
    "\n",
    "# Fit the pipeline to training data.\n",
    "model = pipeline.fit(trainDF)\n",
    "\n",
    "# Evaluate the model on testing data\n",
    "testDF = spark.read.parquet(\"20news_test.parquet\")\n",
    "prediction = model.transform(testDF)\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "print (evaluator.evaluate(prediction))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run the program, you will see that the trained model can only get an [areaUnderROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve) of ~0.75 on the testing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task D - Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it comes to the final task of the assignment. Let's take a look at the above program. It actually used `numFeatures=1000` and `regParam=0.1` to train the model. One natural question is that if we used different values for the two parameters, would that lead to a better model (i.e., a higher areaUnderROC)?\n",
    "\n",
    "\n",
    "In this task, your job is to complete the following code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-560f9f500130>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhashingTF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCrossValidator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimatorParamMaps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparamGrid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumFolds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mcvModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainDF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# Make predictions on test documents. cvModel uses the best model found.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\opt\\spark\\spark-2.2.1-bin-hadoop2.7\\python\\pyspark\\ml\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m     62\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[1;32mC:\\opt\\spark\\spark-2.2.1-bin-hadoop2.7\\python\\pyspark\\ml\\tuning.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    234\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m                 \u001b[1;31m# TODO: duplicate evaluator to take extra params from input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m                 \u001b[0mmetric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meva\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m                 \u001b[0mmetrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnFolds\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\opt\\spark\\spark-2.2.1-bin-hadoop2.7\\python\\pyspark\\ml\\evaluation.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\opt\\spark\\spark-2.2.1-bin-hadoop2.7\\python\\pyspark\\ml\\evaluation.py\u001b[0m in \u001b[0;36m_evaluate\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m     97\u001b[0m         \"\"\"\n\u001b[0;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0misLargerBetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\opt\\spark\\spark-2.2.1-bin-hadoop2.7\\python\\lib\\py4j-0.10.4-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1129\u001b[0m             \u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1131\u001b[1;33m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m   1133\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[1;32mC:\\opt\\spark\\spark-2.2.1-bin-hadoop2.7\\python\\lib\\py4j-0.10.4-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command, retry, binary)\u001b[0m\n\u001b[0;32m    881\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 883\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    884\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\opt\\spark\\spark-2.2.1-bin-hadoop2.7\\python\\lib\\py4j-0.10.4-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command)\u001b[0m\n\u001b[0;32m   1026\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1028\u001b[1;33m             \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1029\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Answer received: {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# The code will tune the following two parameters on the training dataset:\n",
    "# \n",
    "#   numFeatures=1000, 5000, 10000\n",
    "#   regParam=0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9\n",
    "# \n",
    "# and will use 2-fold cross-validation for model evaluation. \n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# for cross validation\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n",
    "lr = LogisticRegression(maxIter=20)\n",
    "\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(hashingTF.numFeatures, [1000, 5000, 10000])\\\n",
    "    .addGrid(lr.regParam, [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\\\n",
    "    .build()\n",
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])\n",
    "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=2)\n",
    "cvModel = cv.fit(trainDF)\n",
    "\n",
    "# Make predictions on test documents. cvModel uses the best model found.\n",
    "best_prediction = cvModel.transform(testDF)\n",
    "best_output = evaluator.evaluate(best_prediction)\n",
    "\n",
    "print (evaluator.evaluate(best_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you get the best model with the best parameters, please apply the model to the testing dataset, and `print` the new areaUnderROC value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download [A6.zip](A6.zip). Complete Tasks A, B, C and D in A6.ipynb, and submit it to the CourSys activity Assignment 6."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
